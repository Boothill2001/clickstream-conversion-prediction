{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“˜ Notebook 02d â€“ Feature Cleaning & Encoding\n",
        "\n",
        "ðŸŽ¯ **Objective:**\n",
        "Clean and preprocess session features:\n",
        "- Handle missing values\n",
        "- Encode categorical columns\n",
        "- Scale numeric features if needed\n",
        "- Save cleaned dataset & log summary\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jiXXfc3QsiyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3TxGJ9TsWSE",
        "outputId": "acd702a0-ca8d-4b8c-cdfe-80112682289a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Downloaded session_features.csv to ../data/session_features.csv\n",
            "âœ… Saved cleaned dataset to ../data/session_features_clean.csv\n",
            "\n",
            "âœ… Feature log saved to ../outputs/feature_log.json\n",
            "{'missing_before': {'user_session': 0, 'num_events': 0, 'num_views': 0, 'num_carts': 0, 'num_purchases': 0, 'avg_price': 0, 'max_price': 0, 'num_categories': 0, 'num_brands': 0, 'session_duration': 0, 'conversion': 0}, 'columns': ['user_session', 'num_events', 'num_views', 'num_carts', 'num_purchases', 'avg_price', 'max_price', 'num_categories', 'num_brands', 'session_duration', 'conversion', 'avg_price_scaled'], 'avg_price_scaled_mean': 8.810729923425242e-17, 'avg_price_scaled_std': 1.0000500037503157}\n",
            "âœ… Uploaded cleaned dataset to GCS â†’ gs://boothill2001-dataset/clickstream/session_features_clean.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.cloud import storage\n",
        "\n",
        "# âœ… Step 1: Download session_features.csv from GCS\n",
        "gcs_path = \"clickstream/session_features.csv\"\n",
        "local_path = \"../data/session_features.csv\"\n",
        "os.makedirs(\"../data\", exist_ok=True)\n",
        "\n",
        "client = storage.Client()\n",
        "bucket = client.bucket(\"boothill2001-dataset\")\n",
        "blob = bucket.blob(gcs_path)\n",
        "blob.download_to_filename(local_path)\n",
        "print(f\"âœ… Downloaded session_features.csv to {local_path}\")\n",
        "\n",
        "# âœ… Step 2: Load DataFrame\n",
        "df = pd.read_csv(local_path)\n",
        "\n",
        "# âœ… Step 3: Handle Missing Values\n",
        "missing_report = df.isnull().sum().to_dict()\n",
        "\n",
        "# âœ… Step 4: Scale numeric features (if applicable)\n",
        "if 'avg_price' in df.columns:\n",
        "    scaler = StandardScaler()\n",
        "    df['avg_price_scaled'] = scaler.fit_transform(df[['avg_price']])\n",
        "    scaled_mean = float(df['avg_price_scaled'].mean())\n",
        "    scaled_std = float(df['avg_price_scaled'].std())\n",
        "else:\n",
        "    scaled_mean = None\n",
        "    scaled_std = None\n",
        "\n",
        "# âœ… Step 5: Save cleaned dataset\n",
        "clean_path = \"../data/session_features_clean.csv\"\n",
        "df.to_csv(clean_path, index=False)\n",
        "print(f\"âœ… Saved cleaned dataset to {clean_path}\")\n",
        "\n",
        "# âœ… Step 6: Log feature transformation summary\n",
        "feature_log = {\n",
        "    \"missing_before\": missing_report,\n",
        "    \"columns\": list(df.columns),\n",
        "    \"avg_price_scaled_mean\": scaled_mean,\n",
        "    \"avg_price_scaled_std\": scaled_std\n",
        "}\n",
        "\n",
        "os.makedirs(\"../outputs\", exist_ok=True)\n",
        "with open(\"../outputs/feature_log.json\", \"w\") as f:\n",
        "    json.dump(feature_log, f, indent=2)\n",
        "\n",
        "print(\"\\nâœ… Feature log saved to ../outputs/feature_log.json\")\n",
        "print(feature_log)\n",
        "\n",
        "# âœ… Optional: Upload cleaned file to GCS\n",
        "upload_path = \"clickstream/session_features_clean.csv\"\n",
        "blob_clean = bucket.blob(upload_path)\n",
        "blob_clean.upload_from_filename(clean_path)\n",
        "print(f\"âœ… Uploaded cleaned dataset to GCS â†’ gs://boothill2001-dataset/{upload_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bwu7UKFTtDeI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}